%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Nome: Jullyana Vycas                                          %
% Disciplina: Recuperação da Informação                         %
%                                                               %
% Esse trabalho trata-se de um estudo do artigo Learning to     %
% Rank with Selection Bias in Personal Search, de autoria de    %
% Xuanhui Wang, Michael Bendersky, Donald Metzler e Marc Najork %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass{svproc}
%
% RECOMMENDED %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%

% Para língua portuguesa
\usepackage[utf8]{inputenc}

% Algoritmos
\usepackage{algorithm} 
\usepackage{algorithmic}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

% to typeset URLs, URIs, and DOIs
\usepackage{url}
\def\UrlFont{\rmfamily}

\begin{document}
\mainmatter              % start of a contribution
%
\title{Learning-to-Rank em Busca Personalizada}
%
\titlerunning{Learning-to-Rank em Busca Personalizada}  % abbreviated title (for running head)
%                                     also used for the TOC unless
%                                     \toctitle is used
%
\author{Jullyana Vycas}
%
\authorrunning{Jullyana Vycas} % abbreviated author list (for running head)
%
%%%% list of authors for the TOC (use if author list has to be modified)
\tocauthor{Jullyana Vycas}
%
\institute{Universidade Federal do Rio de Janeiro, Rio de Janeiro RJ, Brasil,\\
\email{jullytta.ufrj@gmail.com},\\ WWW home page:
\texttt{linkedin.com/in/jullytta}}

\maketitle              % typeset the title of the contribution

\begin{abstract}
Esse trabalho trata-se de um estudo das propostas do artigo
\textit{Learning to Rank with Selection Bias in Personal Search}, incluindo
uma implementação parcial do algoritmo Learning-To-Rank e experimentos
envolvendo os modelos vetorial e probabilístico.

\keywords{learning-to-rank, personal search, BM25, machine learning}
\end{abstract}
%
\section{Introdução}
Novas tecnologias ligadas a inteligência artificial e aprendizado de máquina estão cada vez mais presentes na área
de recuperação da informação, formando os chamados sistemas de recuperação inteligentes \cite{chen}. 
No lugar de especialistas no domínio que manualmente definem a relevância de um documento, entram algoritmos capazes 
de aprender a ranquear. Contudo, esse conhecimento não surge espontâneamente: é preciso obter um conjunto de dados
significativo para servir de exemplo para o algoritmo, ou seja, alimentá-lo.

Aprendemos em sala de aula que pode-se obter feedback dos usuários através de seus cliques. Se apresentamos um ranking 
como resultado de uma consulta, o documento que for acionado pelo usuário (ou seja, aquele que for clicado) provavelmente
é relevante. Portanto, podemos utilizar a avaliação do próprio usuário para descobrir empiricamente a relevância de um 
documento perante uma consulta. Evidentemente, precisamos de usuários fazendo essas buscas e verificando os documentos 
recuperados. Para grandes buscadores na Web, este não é um problema. O buscador Google, por exemplo, lida com
mais de 40.000 consultas por segundo \cite{google:search:statistics}. Cada uma dessas consultas gera dados preciosos
que servirão como exemplo para um algoritmo de aprendizado de máquina.

Contudo, o que acontece no caso em que o domínio é mais restrito? Para buscas dentro de documentos pessoais, sejam eles
e-mails ou arquivos, como descobrimos quais documentos são relevantes? Não podemos nos basear nas milhares de pesquisas
semelhantes que foram feitas anteriormente: os documentos recuperados são privados e diferentes para cada usuário.

Nas próximas seções, nos aprofundaremos no algoritmo Learning-To-Rank em sua forma utilizada para buscas na Web, fazendo 
experimentos sobre o mesmo, simulando uma busca sobre domínio particular. Em seguida, estudaremos as propostas apresentadas 
por Want et al. \cite{wang:bendersky:metzlet:najork} que adaptam o algoritmo para melhor se adequar a buscas personalizadas,
observando as diferentes tendências que podem influenciar a coleta dos dados.


\section{Learning-to-Rank}
Dada uma consulta $q$ e seu conjunto de resultados ${x_1,\dots,x_n}$, o objetivo do algoritmo
é encontrar uma função de ranqueamento $f(x)$ que minimize a perda total.

A definição de perda varia de acordo com a implementação. Neste trabalho, utilizamos uma função de perda par-a-par
simples, sugerida como modelo clássico pelo artigo estudado.

Para cada par $x_i$ e $x_j$ onde $x_i$ é mais relevante que $x_j$, temos:

\begin{equation}
perda_{par} = max(0, f(x_j) - f(x_i))^2
\end{equation}

A perda da função $f$ para com a consulta $q$, ou seja, $perda(f, q)$, é a soma da perda par-a-par para todo 
$x_i, x_j$ indicado acima. Dessa forma, estamos penalizando funções que possuem pares fora de ordem.
Além disso, a perda par-a-par é proporcional à distância entre os ranks.

Digamos que temos um conjunto finito de consultas que o usuário pode fazer, $Q$. 
Selecionamos um subconjunto $U$ de consultas, como amostra aleatória, para avaliar a função $f$.
Assim, a perda total é:

\begin{equation}
perda_{total}(f) = \frac{1}{|U|}\times \sum_{q \in U} perda(f, q)
\end{equation}

Ou seja, uma média aritmética das perdas para cada consulta $q$.

Note que para sermos capazes de calcular a perda apresentada, precisamos conhecer de antemão a ordem decrescente de 
relevância  dos documentos para cada uma das consultas. Vamos discutir como abordar esse problema na próxima seção. 
Por hora, vamos considerar que temos um ``ranking ideal'' contendo essa informação.

\begin{algorithm}
  \caption{Perda Total}
  \begin{algorithmic}[1]
    \REQUIRE conjunto de consultas U, ranking ideal para cada consulta R, função f(x)
    \ENSURE perda total de f
    \STATE $perda_{total} \Leftarrow 0$
    \FOR{$q$ em $U$}
      \STATE $perda_{consulta} \Leftarrow 0$
      \FORALL{$x_i, x_j$ onde $x_i$ aparece antes de $x_j$ em $R$}
	\STATE $perda_{par} \Leftarrow max(0, f(x_j) - f(x_i))^2$
	\STATE $perda_{consulta} \Leftarrow perda_{consulta} + perda_{par}$
      \ENDFOR
      \STATE $perda_{total} \Leftarrow perda_{total} + perda_{consulta}$
    \ENDFOR
    \STATE $perda_{total} \Leftarrow perda_{total} \times \frac{1}{|U|}$
  \end{algorithmic}
\end{algorithm}

Uma vez que definimos nossa avaliação de $f$, é possível aprender qual uma função ótima. Por exemplo, aproveitando a 
implementação feita em sala do ranqueamento BM25, podemos variar os parâmetros $b$ e $K_1$ até encontrar seus 
valores que minimizam a perda total. Assim, ``aprendemos'' uma função de rankeamento para consultas futuras.


\section{Obtendo relevância através de cliques}
Como mencionado anteriormente, para aplicar o algoritmo descrito na seção anterior, precisamos saber de antemão a ordem
de relevância dos documentos. Para descobrí-la, utilizamos o feedback indireto dos usuários, através de cliques.

Vamos começar considerando a situação na qual o usuário fez uma consulta e clica em diversos resultados.
Será que podemos considerá-los relevantes para a consulta? Qual é mais relevante, o que foi clicado primeiro?
Todos os outros documentos não clicados são, então, irrelevantes?

Para responder estas perguntas, precisamos considerar as chamadas \textit{tendências}. O usuário não avalia a relevância
de cada documento apresentado independentemente; o ranqueamento influencia na decisão de clicar ou não em um resultado.
Existem vários tipos diferentes de tendências. A mais comum é a tendência de posição, ou ainda tendência de confiança:
um usuário tende a clicar em resultados com maior rank, tanto por confiar no SRI, quanto pela sua posição.
De fato, estudos mostram que apenas os dois primeiros resultados recebem grande atenção, que cai rapidamente quando 
avaliamos os cinco resultados seguintes \cite{thorsten:granka:pan:hembrooke:gay}.

Outras tendências existem: a tendência de qualidade, na qual a chance do usuário clicar em um resultado
depende da qualidade relativa dele em relação aos outros; a tendência de apresentação, na qual títulos mais atrativos
ou a aparência do resultado influencia na escolha do usuário.


% Bibliografia
\begin{thebibliography}{6}
%

\bibitem {wang:bendersky:metzlet:najork}
Wang, Xuanhui, Bendersky, Michael, Metzler, Donald, Najork, Marc: Learning to Rank with Selection Bias in Personal Search.
SIGIR (2016). \url{https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45286.pdf}

\bibitem {chen}
Chen, Hsinchun: Machine Learning for Information Retrieval: Neural Networks, Symbolic Learning, and Genetic Algorithms.
Journal of the American Society for Information Science (1995). \url{https://www.marilia.unesp.br/Home/Instituicao/Docentes/EdbertoFerneda/chen27.pdf}

\bibitem {google:search:statistics}
Internet Live Stats: Google Search Statistics.
Acesso em 13/06/2017. \url{http://www.internetlivestats.com/google-search-statistics/}

\bibitem {thorsten:granka:pan:hembrooke:gay}
Joachims, Thorsten, Granka, Laura, Pan, Bing, Hembrooke, Helene, Gay, Geri: Accurately Interpreting Clickthrough Data as Implicit
Feedback.
SIGIR (2005). \url{https://www.cs.cornell.edu/people/tj/publications/joachims_etal_05a.pdf}


\end{thebibliography}
\end{document}
